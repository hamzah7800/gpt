<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ultimate Client-Side AI Simulator (JS/ML Tools)</title>
    <link rel="icon" href="icon-192.jpg" type="image/jpeg">

    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjs/12.4.2/math.min.js"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script>
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/nprogress/0.2.0/nprogress.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/nprogress/0.2.0/nprogress.min.js"></script>
    <script src="https://cdn.tailwindcss.com"></script>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/mobilenet"></script>
    <script src="https://unpkg.com/ml5@0.12.2/dist/ml5.min.js"></script>
    <script src="https://docs.opencv.org/4.x/opencv.js" async onload="window.cv=cv"></script> 
    <script src="https://d3js.org/d3.v7.min.js"></script>
    <script src="https://cdn.plot.ly/plotly-2.31.1.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/cannon.js/0.6.2/cannon.min.js"></script> 
    
    <style>
        /* --- General Styling --- */
        body { font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; }
        
        /* --- Animation & Transition Styles --- */
        .thinking-message { background-color: #fff8e1; color: #ff9800; border: 1px solid #ffcc80; animation: pulse 1.5s infinite; }
        @keyframes pulse { 0% { opacity: 0.8; } 50% { opacity: 1; } 100% { opacity: 0.8; } }
        .dot { opacity: 0; animation: dot-fade 1s infinite; }
        .dot:nth-child(2) { animation-delay: 0.2s; }
        .dot:nth-child(3) { animation-delay: 0.4s; }
        @keyframes dot-fade { 0% { opacity: 0; } 50% { opacity: 1; } 100% { opacity: 0; } }
        
        /* Tool Card Styles */
        .tool-card { padding: 0.75rem; margin-bottom: 0rem; border-radius: 0.5rem; }
        .tool-card-math { background-color: #e0f7fa; border: 1px solid #00bcd4; color: #006064; }
        .tool-card-rag { background-color: #e8f5e9; border: 1px solid #4caf50; color: #1b5e20; }
        .tool-card-vision { background-color: #fce4ec; border: 1px solid #e91e63; color: #880e4f; }
        .tool-card-generation { background-color: #e3f2fd; border: 1px solid #2196f3; color: #0d47a1; } 
        .tool-card-code { background-color: #f3e5f5; border: 1px solid #9c27b0; color: #4a148c; }
        .tool-card-api { background-color: #fffde7; border: 1px solid #ffeb3b; color: #f57f17; }
        .tool-card-imagegen { background-color: #e1f5fe; border: 1px solid #03a9f4; color: #01579b; }
        .tool-card-ml { background-color: #f3e8ff; border: 1px solid #9333ea; color: #5b21b6; } 
        .tool-card-vis { background-color: #fff3e0; border: 1px solid #ff9800; color: #e65100; } 
        .tool-card-fallback { background-color: #ffebee; border: 1px solid #f44336; color: #b71c1c; }
        .tool-card-3d { background-color: #f0fdf4; border: 1px solid #10b981; color: #065f46; } /* NEW 3D/Physics Tool Card */


        .response-content { margin-top: 0.5rem; } 

        .voice-recording { background-color: #ef4444; animation: voice-pulse 1s infinite alternate; }
        @keyframes voice-pulse { from { opacity: 1; } to { opacity: 0.7; } }

        @media (max-width: 1200px) {
            .sidebar { position: absolute; z-index: 20; height: 100%; transform: translateX(-100%); transition: transform 0.3s ease; }
            #gameSection.sidebar-visible .sidebar { transform: translateX(0); }
            #sidebarToggle { display: block !important; }
            .chat-interface { overflow: hidden; }
        }
    </style>
</head>
<body class="bg-gray-100 flex justify-center items-center min-h-screen p-4">

    <div id="loginContainer" class="bg-white p-10 rounded-xl shadow-2xl w-full max-w-sm text-center">
        <h1 class="text-3xl text-blue-600 font-bold mb-6">Welcome to the Ultimate Client-Side AI</h1>
        <p class="text-gray-600 mb-4">Login to access the simulator.</p>
        <input type="text" id="username_login" placeholder="Username (ryzen)" class="w-full p-3 mb-4 border border-gray-300 rounded-lg focus:ring-blue-500 focus:border-blue-500">
        <input type="password" id="password_login" placeholder="Key (4060)" class="w-full p-3 mb-6 border border-gray-300 rounded-lg focus:ring-blue-500 focus:border-blue-500">
        <button onclick="validateLogin()" class="w-full p-3 bg-blue-600 text-white font-semibold rounded-lg hover:bg-blue-700 transition duration-200">Login</button>
        <div id="error-message" class="text-red-600 font-bold mt-4"></div>
    </div>

    <div id="gameSection" class="hidden bg-white rounded-xl shadow-2xl w-full max-w-7xl h-[95vh] max-h-[800px] overflow-hidden flex transition-all duration-300">
        
        <div class="sidebar bg-gray-800 text-white w-64 flex flex-col border-r border-gray-700">
            <h2 class="px-5 pt-5 text-lg font-semibold border-b border-gray-700 pb-3 mb-4">Chat History</h2>
            <button class="new-chat-btn mx-5 mb-4 p-2 bg-blue-600 text-white font-medium rounded-lg hover:bg-blue-700 transition" onclick="startNewChat()">+ New Chat</button>
            <ul class="chat-list list-none p-0 m-0 flex-grow overflow-y-auto">
                </ul>
        </div>

        <div class="chat-interface flex-grow flex flex-col relative">
            
            <div id="dropZone" tabindex="-1" class="absolute inset-0 bg-purple-600 bg-opacity-80 text-white hidden justify-center items-center text-2xl z-10 pointer-events-none">Drop Image for ML Classification (TensorFlow.js)</div>

            <div class="chat-header bg-gray-50 p-4 border-b border-gray-200 flex items-center">
                <button id="sidebarToggle" onclick="toggleSidebar()" class="text-xl text-blue-600 mr-4 hidden">&#9776;</button>
                <img src="icon-192.jpg" alt="AI Icon" class="header-icon w-8 h-8 rounded-full object-cover mr-4 border-2 border-blue-500">
                <h3 class="text-lg font-semibold text-gray-800">Ultimate JS Simulator (ML, Vision, Viz, & Physics Tools Active)</h3>
            </div>

            <div id="chatBox" class="flex-grow p-5 overflow-y-auto bg-gray-50 flex flex-col">
                </div>

            <div class="input-container p-4 border-t border-gray-200 flex items-center bg-white">
                <input type="text" id="userInput" placeholder="Ask a question, run code, or drag an image for ML..." autocomplete="off" class="flex-grow p-3 border border-gray-300 rounded-full mr-2 text-base focus:ring-blue-500 focus:border-blue-500">
                
                <button id="voiceBtn" class="input-btn bg-blue-600 text-white w-10 h-10 rounded-full text-xl flex justify-center items-center hover:bg-blue-700 transition ml-2" onclick="toggleVoiceInput()">üé§</button>
                <button id="sendBtn" class="input-btn bg-blue-600 text-white w-10 h-10 rounded-full text-xl flex justify-center items-center hover:bg-blue-700 transition ml-2" onclick="sendMessage()">&#9658;</button>
            </div>
        </div>
    </div>

    <script>
        // GLOBAL STATE VARIABLES
        let lastResponse = '';
        let lastResponseType = 'none'; 
        let currentSessionId = 'session_' + Date.now();
        const HISTORY_ROOT_KEY = 'CLIENT_AI_CHAT_HISTORY';
        let chatContext = []; 
        const mathScope = {}; 
        let isVoiceRecording = false;
        let recognition = null; 
        
        // ML Model State
        let mobilenetModel = null; 
        
        // UI Element References
        const chatBox = document.getElementById('chatBox');
        const userInput = document.getElementById('userInput');
        const chatList = document.querySelector('.chat-list');
        const voiceBtn = document.getElementById('voiceBtn');
        const sendBtn = document.getElementById('sendBtn');
        const dropZone = document.getElementById('dropZone');


// ---------------------------
// 1. INITIALIZATION & SETUP
// ---------------------------

        function validateLogin() {
            // Using unique IDs for login fields
            const username = document.getElementById("username_login").value.trim();
            const password = document.getElementById("password_login").value.trim();
            const errorMessage = document.getElementById("error-message");

            if (username === "ryzen" && password === "4060") {
                document.getElementById("loginContainer").style.display = "none";
                const gameSection = document.getElementById("gameSection");
                gameSection.classList.remove('hidden');
                gameSection.classList.add('flex');

                NProgress.start();
                // Simulate model initialization time
                setTimeout(() => {
                    NProgress.done();
                    initializeChatbotUI();
                }, 500);
            } else {
                errorMessage.textContent = "Invalid username or password. Try again.";
            }
        }
        
        async function initializeChatbotUI() {
            // Load the MobileNet model immediately after login (ML-specific setup)
            try {
                if (window.mobilenet && window.tf) {
                    mobilenetModel = await mobilenet.load();
                    console.log("TensorFlow.js MobileNet Model Loaded Successfully.");
                } else {
                    console.warn("TensorFlow.js or MobileNet not loaded. ML Vision will be mocked.");
                }
            } catch (e) {
                console.error("Error loading MobileNet model:", e);
                // Fallback to mock if loading fails
            }

            // Check for other key libraries
            if (window.d3) console.log("D3.js Loaded for advanced visualization.");
            if (window.Plotly) console.log("Plotly.js Loaded for scientific charts.");
            if (window.ml5) console.log("ml5.js Loaded for easy ML access.");
            if (window.THREE) console.log("Three.js Loaded for 3D rendering.");
            if (window.CANNON) console.log("Cannon.js Loaded for 3D physics.");

            if (sendBtn) sendBtn.addEventListener('click', () => sendMessage());
            if (userInput) userInput.addEventListener('keypress', function (e) {
                if (e.key === 'Enter') sendMessage();
            });
            document.querySelector('.new-chat-btn').addEventListener('click', startNewChat);
            document.getElementById('sidebarToggle').addEventListener('click', toggleSidebar);
            setupDragAndDrop();
            const sessions = loadHistory();
            renderSidebar(sessions);
            renderChatBox(sessions[currentSessionId]);
            userInput.focus();
        }

// ---------------------------
// 2. CORE CHATBOT LOGIC (Tool Dispatch)
// ---------------------------

        const KNOWLEDGE_BASE = [
            { keywords: ['html', 'what html', 'define html', 'html stands for'], response: "**HTML** (HyperText Markup Language) forms the **structure** of web pages." },
            { keywords: ['javascript', 'what is javascript', 'js'], response: "**JavaScript** is the programming language that enables **interactive web pages**." },
            { keywords: ['llm', 'what is llm', 'large language model'], response: "**LLM** (Large Language Model) is a type of AI that can understand and generate human-like text." },
            { keywords: ['tensorflow', 'tfjs', 'machine learning', 'client-side ai'], response: "**TensorFlow.js** is a powerful library for running **Machine Learning models** directly in the browser using JavaScript." },
            { keywords: ['d3.js', 'what is d3'], response: "**D3.js** is the most powerful JavaScript library for creating custom data visualizations using HTML, SVG, and CSS." },
            { keywords: ['plotly', 'scientific charts'], response: "**Plotly.js** is excellent for declarative scientific, statistical, and 3D data visualization in the browser." },
            { keywords: ['css', 'what is css'], response: "**CSS** (Cascading Style Sheets) is used for describing the presentation of a document written in HTML." },
            { keywords: ['webassembly', 'wasm'], response: "**WebAssembly (Wasm)** is a low-level bytecode format designed for high-performance applications on the web, often used for games, video editing, and advanced client-side computations (like OpenCV.js)." },
            { keywords: ['openai', 'gpt', 'chatgpt'], response: "**OpenAI's GPT models** (like ChatGPT) are large language models known for their ability to generate human-like text and perform a wide range of natural language tasks." },
        ];
        
        async function sendMessage(fileDataUrl = null, fileDetails = null) {
            const userText = userInput.value.trim();
            if (!userText && !fileDataUrl) return;

            // 1. Append User Message
            if (userText) appendUserMessage(userText); 
            if (fileDetails) appendUserMessage(`[ML/Vision Prompt] Analyzing file: ${fileDetails.name}`);

            userInput.value = '';
            userInput.disabled = true;
            sendBtn.disabled = true;
            voiceBtn.disabled = true;

            let finalResponse = null;
            let query = userText || (fileDetails ? `Analyze the image: ${fileDetails.name}` : '');
            
            if (userText) {
                chatContext.push(userText);
                if (chatContext.length > 3) chatContext.shift();
            }
            
            const thinkingDiv = appendBotThinking('Processing query with pure JS tools...');
            
            // 2. Tool Execution Logic - PRIORITY ORDER
            
            // 2a. Real-time ML Tool (Highest priority when file dropped with actual model)
            if (fileDataUrl && mobilenetModel) {
                 finalResponse = await clientSideML(fileDataUrl, fileDetails);
                 lastResponseType = 'ml_real';
            }
            // 2b. 3D/Physics Simulation Tool
            else if (!finalResponse) {
                finalResponse = await clientSide3DSimulation(query);
                if (finalResponse) lastResponseType = '3d_real';
            }
            // 2c. Visualization Tool - NOW WITH REAL PLOTLY
            else if (!finalResponse) {
                finalResponse = await clientSideVisualization(query); // Await for Plotly rendering
                if (finalResponse) lastResponseType = 'vis_real';
            }
            // 2d. Vision Tool Mock (Fallback for ML if model not loaded or error)
            else if (fileDetails) {
                 finalResponse = clientSideVisionMock(fileDetails);
                 lastResponseType = 'vision_mock';
            }

            // 2e. Code Execution Mock
            if (!finalResponse) {
                finalResponse = clientSideCodeExecutionMock(query);
                if (finalResponse) lastResponseType = 'code_mock';
            }

            // 2f. Image Generation Mock 
            if (!finalResponse) {
                finalResponse = clientSideImageGenerationMock(query);
                if (finalResponse) lastResponseType = 'image_gen_mock';
            }

            // 2g. API/Live Search Mock 
            if (!finalResponse) {
                finalResponse = clientSideAPIMock(query);
                if (finalResponse) lastResponseType = 'api_mock';
            }

            // 2h. Math Tool 
            if (!finalResponse) {
                const mathResult = clientSideMath(query);
                if (mathResult) {
                    finalResponse = mathResult;
                    lastResponseType = 'math';
                }
            }
            
            // 2i. Simulated Text Generation Tool (General complex queries)
            if (!finalResponse) {
                const essayResult = clientSideEssayGenerator(query);
                if (essayResult) {
                    finalResponse = essayResult;
                    lastResponseType = 'generation_mock';
                }
            }

            // 2j. Keyword/RAG Tool (Factual lookups)
            if (!finalResponse) {
                finalResponse = getKeywordResponse(query.toLowerCase(), chatContext); 
                if (finalResponse) lastResponseType = 'rag'; 
            }

            // 3. Fallback
            if (!finalResponse) {
                finalResponse = getFallbackResponse(query);
                lastResponseType = 'fallback';
            }

            // 4. Render Final Response
            await new Promise(r => setTimeout(r, 800)); 
            thinkingDiv.remove();

            if (finalResponse && typeof finalResponse === 'string' && finalResponse !== 'CHART_RENDERED' && finalResponse !== '3D_SIM_RENDERED') {
                appendBotMessage(finalResponse, true, lastResponseType); 
            }
            
            // 5. Cleanup
            userInput.disabled = false;
            sendBtn.disabled = false;
            voiceBtn.disabled = false;
            userInput.focus();
            renderSidebar(loadHistory());
        }

        function formatToolResponse(content, toolType) {
            let icon = '';
            let title = '';
            let cssClass = `tool-card-fallback`;

            switch (toolType) {
                case 'math': icon = 'üßÆ'; title = 'MATH TOOL (Calculations)'; cssClass = 'tool-card-math'; break;
                case 'rag': icon = 'üìú'; title = 'RAG TOOL (Knowledge Base)'; cssClass = 'tool-card-rag'; break;
                case 'vision_mock': icon = 'üëÅÔ∏è'; title = 'VISION TOOL MOCK (File/Image Analysis)'; cssClass = 'tool-card-vision'; break;
                case 'generation_mock': icon = '‚úçÔ∏è'; title = 'GENERATION TOOL (Simulated Essay)'; cssClass = 'tool-card-generation'; break;
                case 'code_mock': icon = 'üíª'; title = 'CODE EXECUTION MOCK (Copilot/Gemini)'; cssClass = 'tool-card-code'; break;
                case 'api_mock': icon = 'üåê'; title = 'API CALL MOCK (Real-Time Search)'; cssClass = 'tool-card-api'; break;
                case 'image_gen_mock': icon = 'üé®'; title = 'IMAGE GENERATION MOCK (Multi-Modality)'; cssClass = 'tool-card-imagegen'; break;
                case 'ml_real': icon = 'üß†'; title = 'ML TOOL (TensorFlow.js Classification)'; cssClass = 'tool-card-ml'; break;
                case 'vis_real': icon = 'üìà'; title = 'VISUALIZATION TOOL (Plotly.js)'; cssClass = 'tool-card-vis'; break;
                case '3d_real': icon = 'üßä'; title = '3D & PHYSICS SIMULATOR (Three.js/Cannon.js)'; cssClass = 'tool-card-3d'; break;
                default: icon = '‚ùì'; title = 'GENERAL FALLBACK'; break;
            }

            return `<div class="${cssClass} tool-card">
                        <div class="flex items-center mb-2 font-bold border-b border-opacity-30 pb-1">
                            ${icon} <span class="ml-2">${title}</span>
                        </div>
                        <div class="response-content">${content}</div>
                    </div>`;
        }


// **-- Real 3D Physics Simulation Tool (Three.js/Cannon.js) --**

        async function create3DSimulation(simId, setupType) {
            if (!window.THREE || !window.CANNON) {
                console.error("Three.js or Cannon.js not loaded.");
                return;
            }

            const container = document.getElementById(simId);
            if (!container) return;

            // Basic Three.js setup
            const scene = new THREE.Scene();
            const camera = new THREE.PerspectiveCamera(75, container.clientWidth / container.clientHeight, 0.1, 1000);
            const renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
            renderer.setSize(container.clientWidth, container.clientHeight);
            container.appendChild(renderer.domElement);

            // Basic Cannon.js setup
            const world = new CANNON.World();
            world.gravity.set(0, -9.82, 0); 
            world.broadphase = new CANNON.NaiveBroadphase();
            const timeStep = 1 / 60;

            // Shared materials
            const groundMaterial = new CANNON.Material("groundMaterial");
            const sphereMaterial = new CANNON.Material("sphereMaterial");
            const groundSphereContact = new CANNON.ContactMaterial(
                groundMaterial,
                sphereMaterial,
                { friction: 0.4, restitution: 0.8 } 
            );
            world.addContactMaterial(groundSphereContact);

            // 1. Create Ground
            const groundShape = new CANNON.Plane();
            const groundBody = new CANNON.Body({ mass: 0, material: groundMaterial });
            groundBody.addShape(groundShape);
            groundBody.quaternion.setFromAxisAngle(new CANNON.Vec3(1, 0, 0), -Math.PI / 2); // Rotate to horizontal
            world.addBody(groundBody);

            const groundMesh = new THREE.Mesh(
                new THREE.PlaneGeometry(50, 50, 1, 1),
                new THREE.MeshLambertMaterial({ color: 0x444444, side: THREE.DoubleSide })
            );
            groundMesh.rotation.x = -Math.PI / 2;
            scene.add(groundMesh);

            // 2. Lighting and Camera
            scene.add(new THREE.AmbientLight(0x404040));
            const light = new THREE.DirectionalLight(0xffffff, 1.0);
            light.position.set(5, 5, 5);
            scene.add(light);
            camera.position.set(0, 5, 10);
            camera.lookAt(0, 0, 0);

            let meshes = [];
            let bodies = [];

            // 3. Add Objects based on setupType
            if (setupType === 'blocks') {
                for (let i = 0; i < 5; i++) {
                    const size = 1 + Math.random();
                    const boxShape = new CANNON.Box(new CANNON.Vec3(size / 2, size / 2, size / 2));
                    const boxBody = new CANNON.Body({ mass: size, position: new CANNON.Vec3(Math.random() * 4 - 2, 10 + i * 2, Math.random() * 4 - 2) });
                    boxBody.addShape(boxShape);
                    world.addBody(boxBody);
                    bodies.push(boxBody);

                    const boxMesh = new THREE.Mesh(
                        new THREE.BoxGeometry(size, size, size),
                        new THREE.MeshLambertMaterial({ color: Math.random() * 0xffffff })
                    );
                    scene.add(boxMesh);
                    meshes.push(boxMesh);
                }
            } else { // 'spheres' or default
                for (let i = 0; i < 10; i++) {
                    const radius = 0.5 + Math.random() * 0.5;
                    const sphereShape = new CANNON.Sphere(radius);
                    const sphereBody = new CANNON.Body({ mass: radius, position: new CANNON.Vec3(Math.random() * 4 - 2, 5 + i * 1, Math.random() * 4 - 2), material: sphereMaterial });
                    world.addBody(sphereBody);
                    bodies.push(sphereBody);

                    const sphereMesh = new THREE.Mesh(
                        new THREE.SphereGeometry(radius, 16, 16),
                        new THREE.MeshLambertMaterial({ color: Math.random() * 0xffffff })
                    );
                    scene.add(sphereMesh);
                    meshes.push(sphereMesh);
                }
            }
            
            // 4. Animation Loop
            let lastTime = 0;
            function animate(time) {
                requestAnimationFrame(animate);
                
                // Calculate delta time
                const dt = (time - lastTime) / 1000;
                if (dt < 1 / 60) {
                     // Prevent excessive updates when tab is hidden
                    lastTime = time;
                    return;
                }
                world.step(timeStep, dt);

                // Update three.js meshes
                for (let i = 0; i < meshes.length; i++) {
                    meshes[i].position.copy(bodies[i].position);
                    meshes[i].quaternion.copy(bodies[i].quaternion);
                }
                
                renderer.render(scene, camera);
                lastTime = time;
            }

            animate(0);
        }

        async function clientSide3DSimulation(input) {
            const lowQuery = input.toLowerCase();
            const simKeywords = ['create a 3d simulation', 'simulate physics', 'three.js', 'cannon.js', 'drop cubes', 'drop spheres', '3d environment'];
            if (!simKeywords.some(keyword => lowQuery.includes(keyword))) return null;

            if (!window.THREE || !window.CANNON) {
                return formatToolResponse(`**3D Simulation Error:** Three.js or Cannon.js not loaded. Cannot run client-side physics.`, '3d_real');
            }

            const simId = `physics-sim-${Date.now()}`;
            let setupType = lowQuery.includes('blocks') || lowQuery.includes('cubes') ? 'blocks' : 'spheres';

            const responseHtml = `
                ### **Live 3D Physics Simulation (Three.js + Cannon.js)**
                **Simulation Type:** <code>${setupType.toUpperCase()} Drop Test</code>
                **Engine:** <code>Three.js (Renderer) & Cannon.js (Physics)</code>
                **Output:**
                <div id="${simId}" style="height: 350px; width: 100%; background-color: #add8e6;" class="rounded-lg shadow-md mt-2"></div>
                **Note:** This interactive 3D simulation runs entirely in your browser. Objects are generated and follow real-time physics (gravity, collision, restitution).
            `;
            
            // Append the message first so the div exists
            appendBotMessage(formatToolResponse(responseHtml, '3d_real'), false); 
            
            // Render the 3D scene after the div is in the DOM
            // Use a slight delay to ensure browser has painted the div
            await new Promise(resolve => setTimeout(resolve, 50)); 
            await create3DSimulation(simId, setupType);

            // Save to history after rendering
            saveCurrentChat(null, formatToolResponse(responseHtml, '3d_real'));
            lastResponse = formatToolResponse(responseHtml, '3d_real');
            
            return '3D_SIM_RENDERED'; // Indicate that a simulation was rendered
        }


// **-- Real Plotly.js Visualization Tool --**
        /**
         * Dynamically creates and plots a chart using Plotly.js.
         */
        async function createPlotlyChart(chartId, data, layout) {
            if (!window.Plotly) return;
            let chartDiv = document.getElementById(chartId);
            if (!chartDiv) return;
            await Plotly.newPlot(chartId, data, layout);
        }

        async function clientSideVisualization(input) {
            const lowQuery = input.toLowerCase();
            const vizKeywords = ['create a graph', 'show me data', 'visualize', 'plot', 'bar chart', 'line chart', 'pie chart', 'scatter plot'];
            if (!vizKeywords.some(keyword => lowQuery.includes(keyword))) return null;

            if (!window.Plotly) {
                return formatToolResponse(`Plotly.js not fully loaded yet. Please try again in a moment.`, 'vis_real');
            }

            const chartId = `plotly-chart-${Date.now()}`;
            let data = [];
            let layout = {
                title: 'Simulated Data Visualization',
                height: 300,
                margin: {t: 40, b: 40, l: 40, r: 40}
            };

            // Generate some dynamic data based on query
            if (lowQuery.includes('bar chart') || lowQuery.includes('bar graph')) {
                data.push({
                    x: ['A', 'B', 'C', 'D', 'E'],
                    y: [Math.floor(Math.random() * 100), Math.floor(Math.random() * 100), Math.floor(Math.random() * 100), Math.floor(Math.random() * 100), Math.floor(Math.random() * 100)],
                    type: 'bar',
                    marker: { color: 'rgba(50,171,96,0.7)' }
                });
                layout.title = 'Simulated Bar Chart: Category Performance';
                layout.xaxis = { title: 'Category' };
                layout.yaxis = { title: 'Value' };
            } else if (lowQuery.includes('line chart') || lowQuery.includes('line graph')) {
                const x = Array.from({length: 10}, (_, i) => i + 1);
                const y1 = x.map(val => Math.sin(val / 2) * 20 + 50 + Math.random() * 10);
                const y2 = x.map(val => Math.cos(val / 2) * 15 + 40 + Math.random() * 10);
                data.push({
                    x: x, y: y1, mode: 'lines+markers', name: 'Series 1',
                    line: { color: '#1f77b4' }, marker: { size: 8 }
                });
                 data.push({
                    x: x, y: y2, mode: 'lines+markers', name: 'Series 2',
                    line: { color: '#ff7f0e' }, marker: { size: 8 }
                });
                layout.title = 'Simulated Line Chart: Trend Over Time';
                layout.xaxis = { title: 'Time Point' };
                layout.yaxis = { title: 'Measurement' };
            } else if (lowQuery.includes('pie chart')) {
                 data.push({
                    labels: ['Success', 'Failure', 'Pending'],
                    values: [Math.floor(Math.random() * 50) + 20, Math.floor(Math.random() * 30) + 10, Math.floor(Math.random() * 20) + 5],
                    type: 'pie',
                    hoverinfo: 'label+percent',
                    textinfo: 'percent',
                    hole: .4,
                    marker: { colors: ['#28a745', '#dc3545', '#ffc107'] }
                 });
                 layout.title = 'Simulated Pie Chart: Status Distribution';
                 layout.showlegend = true;
            } else if (lowQuery.includes('scatter plot')) {
                const x = Array.from({length: 50}, () => Math.random() * 100);
                const y = x.map(val => val * 0.8 + (Math.random() - 0.5) * 20); // Some correlation
                data.push({
                    x: x, y: y, mode: 'markers', name: 'Data Points',
                    marker: { size: 8, color: '#9333ea', opacity: 0.7 }
                });
                layout.title = 'Simulated Scatter Plot: Correlation Analysis';
                layout.xaxis = { title: 'Feature X' };
                layout.yaxis = { title: 'Feature Y' };
            }
            else { // Default to a simple bar chart
                data.push({
                    x: ['Metric 1', 'Metric 2', 'Metric 3'],
                    y: [75, 42, 91],
                    type: 'bar',
                    marker: { color: 'rgba(0,123,255,0.7)' }
                });
                layout.title = 'Default Simulated Metrics';
                layout.xaxis = { title: 'Metric' };
                layout.yaxis = { title: 'Score' };
            }
            
            const responseHtml = `
                ### **Visualization Report (Plotly.js)**
                **Chart Type:** <code>${layout.title.replace('Simulated ', '').split(':')[0].trim()}</code>
                **Engine:** <code>Plotly.js (Client-Side)</code>
                **Output:**
                <div id="${chartId}" style="height: 300px; width: 100%;" class="bg-white rounded-lg shadow-md p-2 mt-2"></div>
                **Note:** The interactive chart above was generated directly in your browser using Plotly.js. You can zoom, pan, and hover over data points.
            `;
            
            // Append the message first so the div exists
            appendBotMessage(formatToolResponse(responseHtml, 'vis_real'), false); 
            
            // Render the Plotly chart after the div is in the DOM
            await createPlotlyChart(chartId, data, layout);

            // Save to history after Plotly is done, ensuring the HTML content for the div is there
            saveCurrentChat(null, formatToolResponse(responseHtml, 'vis_real'));
            lastResponse = formatToolResponse(responseHtml, 'vis_real');
            
            return 'CHART_RENDERED'; // Indicate that a chart was rendered
        }


        /**
         * Helper function to wait for an image element to load its source.
         * This is CRITICAL to fix the TensorFlow.js "texture size [0x0]" error.
         */
        function loadImage(imgElement) {
            return new Promise((resolve, reject) => {
                if (imgElement.complete && imgElement.naturalHeight !== 0) {
                    return resolve();
                }
                imgElement.onload = () => resolve();
                imgElement.onerror = (e) => reject(new Error('Image failed to load.'));
            });
        }
        
        async function clientSideML(fileDataUrl, fileDetails) {
            if (!mobilenetModel) {
                 return formatToolResponse(`**Classification Error:** MobileNet model not loaded. ML Vision will be mocked.`, 'ml_real');
            }

            const tempImg = document.createElement('img');
            tempImg.src = fileDataUrl;
            tempImg.style.display = 'none'; // Keep hidden
            document.body.appendChild(tempImg);

            let predictions = [];
            let errorOccurred = false;
            let errorMessage = '';

            try {
                await loadImage(tempImg); 
                predictions = await mobilenetModel.classify(tempImg);
            } catch (e) {
                errorOccurred = true;
                errorMessage = e.message;
                console.error("ML Classification Failed:", e);
            } finally {
                if (document.body.contains(tempImg)) {
                    document.body.removeChild(tempImg);
                }
            }

            if (errorOccurred) {
                return formatToolResponse(`**Classification Error:** The ML Model (${fileDetails.name}) encountered an issue: <code>${errorMessage}</code>. This might happen with very small or corrupted images.`, 'ml_real');
            }

            if (predictions.length === 0) {
                 return formatToolResponse(`**Classification Result:** No clear classification found by MobileNet. This could be due to the image content being outside its training data (e.g., highly stylized art).`, 'ml_real');
            }

            const topPrediction = predictions[0];
            const confidence = Math.round(topPrediction.probability * 100);

            let analysis = `
                ### **Real-Time ML Classification (TensorFlow.js)**
                **Input File:** <code>${fileDetails.name}</code>
                
                **Top Prediction:**
                - **Class:** <code>**${topPrediction.className}**</code>
                - **Confidence:** <code>${confidence}%</code>
                
                **Detailed Results:**
                <ol class="list-decimal list-inside mt-2">
                    ${predictions.slice(0, 5).map(p => `<li><code>${p.className}</code> (<code>${Math.round(p.probability * 100)}%</code>)</li>`).join('')}
                </ol>
                
                **Engine:** <code>MobileNet (Pre-trained on ImageNet)</code>
            `;

            if (confidence < 20 && !topPrediction.className.toLowerCase().includes('comic book') && !topPrediction.className.toLowerCase().includes('illustration')) {
                 analysis += `<div class="mt-3 p-2 bg-yellow-100 border border-yellow-400 rounded-md text-sm text-yellow-800">
                    ‚ö†Ô∏è **Low Confidence & Potential Mismatch:** The model is highly uncertain. MobileNet is primarily trained on real-world photos, so it often struggles with highly stylized art like anime. This explains why it might guess things like "French horn" for a character's features!
                </div>`;
            }

            return formatToolResponse(analysis, 'ml_real');
        }

        function clientSideVisionMock(imageDetails) {
            const sizeKB = Math.round(imageDetails.size / 1024);
            const fileName = imageDetails.name;
            const mockCategories = fileName.toLowerCase().includes('server') || fileName.toLowerCase().includes('data') ? 
                'Server Infrastructure, Network Hardware, Data Center' : 
                'Abstract Concept, User Interface Element, General Photography, Illustration';
            const mockResolution = '1920x1080 (Simulated)'; 

            const analysis = `
                ### **Simulated Visual Analysis Report (OpenCV/ML5 Mock)**
                
                | Metric | Result |
                | :--- | :--- |
                | **File Name** | <code>${fileName}</code> |
                | **File Size** | <code>${sizeKB} KB</code> |
                | **Simulated Resolution** | <code>${mockResolution}</code> |
                | **Primary Categories** | <code>${mockCategories}</code> |
                | **Assessment** | **MOCK:** Low-level image analysis using simulated **OpenCV.js** processing pipeline. For real classification, use a valid ML model. This mock suggests the image is an illustration, which is a better conceptual fit for anime. |
            `;
            
            return formatToolResponse(analysis, 'vision_mock');
        }
        
        function getKeywordResponse(input, context) {
            let bestMatch = null;
            let maxConfidence = 0.15; 
            const fullQuery = [...context, input].join(' ').toLowerCase();
            for (const item of KNOWLEDGE_BASE) {
                for (const keyword of item.keywords) {
                    const confidence = jaccardSimilarity(fullQuery, keyword);
                    if (confidence > maxConfidence) {
                        maxConfidence = confidence;
                        bestMatch = item;
                    }
                }
            }
            if (bestMatch) return formatToolResponse(`[RAG TOOL SEARCH RESULT - Confidence: ${Math.round(maxConfidence * 100)}%] ${bestMatch.response}`, 'rag');
            return null;
        }

        function jaccardSimilarity(str1, str2) {
             str1 = str1.toLowerCase().replace(/\s/g, '');
            str2 = str2.toLowerCase().replace(/\s/g, '');
            if (str1.length < 2 || str2.length < 2) { return str1.includes(str2) || str2.includes(str1) ? 1.0 : 0.0; }
            const getNGrams = (s, n = 2) => {
                const ngrams = new Set();
                for (let i = 0; i <= s.length - n; i++) ngrams.add(s.substring(i, i + n));
                return ngrams;
            };
            const set1 = getNGrams(str1);
            const set2 = getNGrams(str2);
            let intersection = 0;
            for (const gram of set1) { if (set2.has(gram)) intersection++; }
            const union = set1.size + set2.size - intersection;
            return union === 0 ? 0 : intersection / union;
        }
        
        function clientSideMath(input) {
            const lowQuery = input.toLowerCase();
            const mathPattern = /(calculate|solve|what is|compute|evaluate|result of)\s+([\s\S]+)/i;
            const match = lowQuery.match(mathPattern);

            if (!match) return null;

            let expression = match[2].trim().replace(/\?/g, '');
            let result;

            try {
                // Remove common preamble from the expression
                expression = expression
                    .replace(/the equation/g, '')
                    .replace(/the expression/g, '')
                    .replace(/the sum of/g, '')
                    .trim();

                // Basic validation and security check before evaluation
                if (!/^[a-z0-9\s\+\-\*\/\^\(\)\.\,\!\=\<\>]+$/i.test(expression)) {
                    throw new Error("Invalid characters detected in expression.");
                }
                
                result = math.evaluate(expression, mathScope);
                
                // Check if result is a function or undefined
                if (typeof result === 'function' || result === undefined || (typeof result === 'object' && result.isNode)) {
                    return null; // Don't process non-scalar or incomplete math results
                }

                const latexResult = katex.renderToString(math.parse(expression).toLatex() + ' = ' + math.format(result, {precision: 5}), { displayMode: true, throwOnError: false });
                
                // Store/update variable in scope if assignment was detected (e.g., a = 5)
                const assignmentMatch = expression.match(/([a-zA-Z]+)\s*=\s*([\s\S]+)/);
                if (assignmentMatch) {
                    const varName = assignmentMatch[1].trim();
                    mathScope[varName] = result;
                    return formatToolResponse(`**Assignment:** Variable \`${varName}\` set to \`${math.format(result)}\`.<br>**Result:** ${latexResult}`, 'math');
                }

                return formatToolResponse(`**Expression:** ${latexResult}`, 'math');

            } catch (error) {
                console.warn("Math error:", error.message);
                // Only return an error if the user explicitly asked for a calculation
                if (mathPattern.test(lowQuery)) {
                    return formatToolResponse(`**Math Error:** Could not evaluate expression. **Error:** <code>${error.message}</code>. Try simplifying the query or ensuring it's a valid mathematical expression.`, 'math');
                }
                return null;
            }
        }

        function clientSideCodeExecutionMock(input) {
            const lowQuery = input.toLowerCase();
            const codeKeywords = ['write a function', 'in javascript', 'in python', 'show me the code for', 'generate a script'];
            if (!codeKeywords.some(keyword => lowQuery.includes(keyword))) return null;

            const language = lowQuery.includes('python') ? 'python' : 'javascript';
            const subject = input.replace(/.*code for|write a function for/i, '').trim() || 'an algorithm';
            
            let mockCode = '';
            if (language === 'javascript') {
                mockCode = `
// JavaScript function to calculate the ${subject}
function calculate${subject.replace(/\s+/g, '')}() {
  // Logic generated by Code Tool
  const inputData = [10, 20, 30];
  let result = inputData.reduce((a, b) => a + b, 0) / inputData.length;
  console.log('Processed result:', result);
  return result;
}

// Execution:
calculate${subject.replace(/\s+/g, '')}(); 
`;
            } else {
                mockCode = `
# Python script to calculate the ${subject}
def calculate_${subject.replace(/\s+/g, '_')}():
    # Logic generated by Code Tool
    input_data = [10, 20, 30]
    result = sum(input_data) / len(input_data)
    print(f"Processed result: {result}")
    return result

# Execution:
calculate_${subject.replace(/\s+/g, '_')}()
`;
            }

            const response = `
                ### **Simulated Code Generation**
                **Query:** <code>${input}</code>
                **Language:** <code>${language}</code>
                **Engine:** <code>Simulated Copilot/Gemini-Code Tool</code>
                <pre class="bg-gray-800 text-white p-3 rounded-md text-sm overflow-x-auto mt-2"><code>${mockCode.trim()}</code></pre>
                **Status:** **MOCK SUCCESS:** Code generated and simulated execution result logged to the console.
            `;
            return formatToolResponse(response, 'code_mock');
        }

        function clientSideImageGenerationMock(input) {
            const lowQuery = input.toLowerCase();
            const genKeywords = ['generate an image of', 'create a picture of', 'draw', 'dalle', 'stable diffusion'];
            if (!genKeywords.some(keyword => lowQuery.includes(keyword))) return null;

            const prompt = input.replace(/.*(generate an image of|create a picture of|draw)\s+a/i, '').trim();
            const imageUrl = "https://picsum.photos/400/200?random=" + Date.now();
            
            const response = `
                ### **Simulated Image Generation (Multi-Modality Mock)**
                **Prompt:** <code>**${prompt}**</code>
                **Engine:** <code>Simulated Diffusion Model (DALL-E/Imagen)</code>
                <div class="mt-2 text-center">
                    <img src="${imageUrl}" alt="Simulated generated image of ${prompt}" class="w-full max-w-sm rounded-lg shadow-xl mx-auto border-4 border-blue-200">
                    <p class="text-xs text-gray-500 mt-1"><em>Simulated result using Placeholder Image API.</em></p>
                </div>
                **Status:** **MOCK SUCCESS:** Image successfully generated based on your text prompt.
            `;
            return formatToolResponse(response, 'image_gen_mock');
        }

        function clientSideAPIMock(input) {
            const lowQuery = input.toLowerCase();
            const apiKeywords = ['latest news', 'what is the current price of', 'stock price', 'weather in', 'live search'];
            if (!apiKeywords.some(keyword => lowQuery.includes(keyword))) return null;

            let topic = '';
            let resultText = '';

            if (lowQuery.includes('news')) {
                topic = 'Global Markets';
                resultText = 'Major indices are up slightly, driven by positive earnings reports from tech firms. Volatility remains low.';
            } else if (lowQuery.includes('stock price') || lowQuery.includes('price of')) {
                topic = 'TSLA Stock Price';
                resultText = '$285.50 at market close on 2025-10-04. (Simulated Real-Time Data)';
            } else if (lowQuery.includes('weather')) {
                topic = 'Weather';
                resultText = 'Cloudy with a high of 15¬∞C in Birmingham, UK. Chance of rain 30%. (Simulated API Call)';
            } else {
                topic = 'General Real-Time Information';
                resultText = 'The current time is 10:09 PM BST on Saturday, October 4, 2025. This information was retrieved via a simulated Google Search API call.';
            }

            const response = `
                ### **Simulated Real-Time API Call**
                **API Target:** <code>${topic}</code>
                **Query:** <code>${input}</code>
                **Result:** **${resultText}**
                **Engine:** <code>Simulated Live Search/API Connector</code>
            `;
            return formatToolResponse(response, 'api_mock');
        }

        function clientSideEssayGenerator(input) {
            const lowQuery = input.toLowerCase();
            const genKeywords = ['write a paragraph about', 'explain the concept of', 'generate an essay on', 'in depth analysis of'];
            if (!genKeywords.some(keyword => lowQuery.includes(keyword))) return null;

            const topic = input.replace(/.*(write a paragraph about|explain the concept of|generate an essay on|in depth analysis of)/i, '').trim() || 'Generative AI';
            const wordCount = lowQuery.includes('essay') ? '300 words' : '50 words';
            
            const generatedText = `
                ### **Simulated Text Generation**
                **Topic:** <code>**${topic}**</code>
                **Length:** <code>${wordCount}</code>
                **Engine:** <code>Simulated LLM (GPT-4)</code>
                <p class="mt-2 p-2 bg-gray-50 rounded-md">
                    The concept of **${topic}** represents a paradigm shift in computing, moving from traditional deterministic code to probabilistic, large-scale model inference. These models, often trained on massive datasets, excel at pattern recognition and content creation across text, image, and code modalities. The client-side deployment of such models, utilizing libraries like **TensorFlow.js** and **WebAssembly**, is crucial for enhancing user privacy and achieving low-latency, real-time performance directly within the user's browser, bypassing the need for constant server communication. This distributed intelligence is the future of interactive web applications.
                </p>
                **Status:** **MOCK SUCCESS:** Long-form content generated.
            `;
            return formatToolResponse(generatedText, 'generation_mock');
        }

        function getFallbackResponse(query) {
            const advice = "I couldn't match your query to any active client-side tools (Math, ML, Viz, or Physics) or my knowledge base. Try asking a question about a JavaScript library, a math equation, or prompting for a visualization.";
            return formatToolResponse(`**Query:** "${query}"<br><br>${advice}`, 'fallback');
        }


// ---------------------------
// 3. UI RENDERING & STORAGE
// ---------------------------

        function appendBotThinking(message) {
            const thinkingDiv = document.createElement('div');
            thinkingDiv.className = 'message bot-message thinking-message max-w-lg p-3 rounded-lg self-start mb-4 shadow-md';
            thinkingDiv.innerHTML = `${message} <span class="dot">.</span><span class="dot">.</span><span class="dot">.</span>`;
            chatBox.appendChild(thinkingDiv);
            chatBox.scrollTop = chatBox.scrollHeight;
            return thinkingDiv;
        }

        function appendUserMessage(text) {
            const userDiv = document.createElement('div');
            userDiv.className = 'message user-message bg-blue-500 text-white max-w-xl p-3 rounded-xl rounded-br-none self-end mb-4 shadow-md';
            userDiv.innerHTML = `<p>${text}</p>`;
            chatBox.appendChild(userDiv);
            saveCurrentChat(text, null);
            chatBox.scrollTop = chatBox.scrollHeight;
        }

        function appendBotMessage(text, save = true, toolType = 'fallback') {
            const botDiv = document.createElement('div');
            botDiv.className = 'message bot-message bg-white text-gray-800 max-w-3xl p-3 rounded-xl rounded-tl-none self-start mb-4 shadow-xl';
            botDiv.innerHTML = text;
            chatBox.appendChild(botDiv);
            
            // Re-render math content if present
            if (window.renderMathInElement) {
                renderMathInElement(botDiv);
            }

            if (save) {
                saveCurrentChat(null, text, toolType);
            }
            chatBox.scrollTop = chatBox.scrollHeight;
            lastResponse = text;
        }

        function loadHistory() {
            try {
                const history = localStorage.getItem(HISTORY_ROOT_KEY);
                return history ? JSON.parse(history) : { [currentSessionId]: { title: 'New Chat', messages: [] } };
            } catch (e) {
                console.error("Could not load chat history:", e);
                return { [currentSessionId]: { title: 'New Chat', messages: [] } };
            }
        }

        function saveHistory(history) {
            try {
                localStorage.setItem(HISTORY_ROOT_KEY, JSON.stringify(history));
            } catch (e) {
                console.error("Could not save chat history:", e);
            }
        }

        function saveCurrentChat(userText, botText, toolType) {
            let history = loadHistory();
            if (!history[currentSessionId]) {
                history[currentSessionId] = { title: 'New Chat', messages: [] };
            }

            if (userText) {
                history[currentSessionId].messages.push({ sender: 'user', text: userText });
                if (history[currentSessionId].messages.length === 1 && userText.length > 5) {
                    history[currentSessionId].title = userText.substring(0, 20) + '...';
                }
            }
            
            if (botText) {
                // Only save the full HTML response for the bot
                history[currentSessionId].messages.push({ sender: 'bot', text: botText, tool: toolType });
            }
            
            saveHistory(history);
        }

        function renderSidebar(sessions) {
            chatList.innerHTML = '';
            const sessionIds = Object.keys(sessions).sort((a, b) => {
                // Sort by most recent message first
                const aTime = sessions[a].messages.length > 0 ? sessions[a].messages[sessions[a].messages.length - 1].timestamp || 0 : 0;
                const bTime = sessions[b].messages.length > 0 ? sessions[b].messages[sessions[b].messages.length - 1].timestamp || 0 : 0;
                return bTime - aTime;
            });

            sessionIds.forEach(id => {
                const session = sessions[id];
                const listItem = document.createElement('li');
                listItem.className = `p-3 mx-3 mb-2 rounded-lg cursor-pointer transition ${id === currentSessionId ? 'bg-blue-600 font-semibold' : 'hover:bg-gray-700'}`;
                listItem.textContent = session.title || id;
                listItem.onclick = () => switchChatSession(id);
                chatList.appendChild(listItem);
            });
        }

        function renderChatBox(session) {
            chatBox.innerHTML = '';
            if (session && session.messages) {
                session.messages.forEach(msg => {
                    if (msg.sender === 'user') {
                        appendUserMessage(msg.text);
                    } else if (msg.sender === 'bot') {
                        appendBotMessage(msg.text, false, msg.tool); // Do not save again when rendering from history
                    }
                });
            } else {
                 appendBotMessage(formatToolResponse("Welcome! I am the **Ultimate Client-Side AI Simulator**. I use various **JavaScript Libraries** (TensorFlow.js, Plotly.js, Three.js, etc.) to process your requests directly in the browser. Try asking me to: <ul><li><code>calculate sin(pi/4)</code></li><li><code>create a line chart of trends</code></li><li><code>generate an image of a unicorn in the sun</code></li><li><code>create a 3d simulation of dropping spheres</code></li><li>**Drag and drop an image** for real-time ML analysis!</ul>", 'rag'), false);
            }
             chatBox.scrollTop = chatBox.scrollHeight;
        }

        function startNewChat() {
            currentSessionId = 'session_' + Date.now();
            chatContext = [];
            mathScope = {};
            renderSidebar(loadHistory());
            renderChatBox(null);
            if (document.getElementById("gameSection").classList.contains('sidebar-visible')) {
                toggleSidebar(); // Hide sidebar on mobile after new chat
            }
        }

        function switchChatSession(id) {
            currentSessionId = id;
            chatContext = [];
            mathScope = {}; // Reset scope for each session
            const sessions = loadHistory();
            renderSidebar(sessions);
            renderChatBox(sessions[currentSessionId]);
            if (document.getElementById("gameSection").classList.contains('sidebar-visible')) {
                toggleSidebar(); // Hide sidebar on mobile after switching
            }
        }

        function toggleSidebar() {
            document.getElementById("gameSection").classList.toggle('sidebar-visible');
            document.querySelector('.sidebar').classList.toggle('hidden');
        }


// ---------------------------
// 4. VOICE & FILE INPUT HANDLERS
// ---------------------------

        function toggleVoiceInput() {
            if (!('webkitSpeechRecognition' in window)) {
                alert("Voice input not supported in this browser. Please use Chrome.");
                return;
            }

            if (isVoiceRecording) {
                recognition.stop();
                isVoiceRecording = false;
                voiceBtn.classList.remove('voice-recording', 'bg-red-600');
                voiceBtn.classList.add('bg-blue-600');
                voiceBtn.innerHTML = 'üé§';
            } else {
                recognition = new webkitSpeechRecognition();
                recognition.continuous = false;
                recognition.interimResults = false;
                recognition.lang = 'en-US';

                recognition.onstart = function() {
                    isVoiceRecording = true;
                    voiceBtn.classList.add('voice-recording', 'bg-red-600');
                    voiceBtn.classList.remove('bg-blue-600');
                    voiceBtn.innerHTML = 'üî¥';
                };

                recognition.onresult = function(event) {
                    const transcript = event.results[0][0].transcript;
                    userInput.value = transcript;
                    sendMessage();
                };

                recognition.onerror = function(event) {
                    console.error('Speech recognition error:', event.error);
                    voiceBtn.classList.remove('voice-recording', 'bg-red-600');
                    voiceBtn.classList.add('bg-blue-600');
                    voiceBtn.innerHTML = 'üé§';
                    alert(`Voice Error: ${event.error}`);
                };

                recognition.onend = function() {
                    isVoiceRecording = false;
                    voiceBtn.classList.remove('voice-recording', 'bg-red-600');
                    voiceBtn.classList.add('bg-blue-600');
                    voiceBtn.innerHTML = 'üé§';
                };

                recognition.start();
            }
        }


        function setupDragAndDrop() {
            const preventDefaults = (e) => {
                e.preventDefault();
                e.stopPropagation();
            };

            const highlight = () => {
                dropZone.classList.remove('hidden');
                dropZone.classList.add('flex');
            };

            const unhighlight = () => {
                dropZone.classList.add('hidden');
                dropZone.classList.remove('flex');
            };

            ['dragenter', 'dragover', 'dragleave', 'drop'].forEach(eventName => {
                document.addEventListener(eventName, preventDefaults, false);
            });

            ['dragenter', 'dragover'].forEach(eventName => {
                document.addEventListener(eventName, highlight, false);
            });

            ['dragleave', 'drop'].forEach(eventName => {
                document.addEventListener(eventName, unhighlight, false);
            });

            document.addEventListener('drop', handleDrop, false);

            function handleDrop(e) {
                const dt = e.dataTransfer;
                const files = dt.files;

                if (files.length > 0) {
                    const file = files[0];
                    if (file.type.startsWith('image/')) {
                        const reader = new FileReader();
                        reader.onload = function(event) {
                            const fileDataUrl = event.target.result;
                            const fileDetails = { name: file.name, size: file.size, type: file.type };
                            sendMessage(fileDataUrl, fileDetails);
                        };
                        reader.readAsDataURL(file);
                    } else {
                        alert("Only image files are supported for ML analysis.");
                    }
                }
            }
        }
    </script>
</body>
</html>
