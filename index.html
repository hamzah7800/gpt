<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ultimate Client-Side AI Simulator (JS/ML Tools)</title>
    <link rel="icon" href="icon-192.jpg" type="image/jpeg">

    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjs/12.4.2/math.min.js"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script>
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/nprogress/0.2.0/nprogress.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/nprogress/0.2.0/nprogress.min.js"></script>
    <script src="https://cdn.tailwindcss.com"></script>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/mobilenet"></script>
    <script src="https://unpkg.com/ml5@0.12.2/dist/ml5.min.js"></script>
    <script src="https://cdn.plot.ly/plotly-2.29.1.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/cannon-es@0.20.0/dist/cannon-es.min.js"></script>
    <script src="https://d3js.org/d3.v5.min.js"></script>
    
    <script async src="https://docs.opencv.org/4.7.0/opencv.js" onload="onOpenCvReady();" type="text/javascript"></script>

    <style>
        .chat-message-user {
            background-color: #3b82f6; /* blue-500 */
            align-self: flex-end;
            border-bottom-right-radius: 0;
        }
        .chat-message-ai {
            background-color: #1f2937; /* gray-800 */
            align-self: flex-start;
            border-bottom-left-radius: 0;
        }
        #chat-window::-webkit-scrollbar {
            display: none;
        }
        #chat-window {
            -ms-overflow-style: none; /* IE and Edge */
            scrollbar-width: none; /* Firefox */
        }
    </style>
</head>
<body class="bg-gray-900 text-white flex flex-col h-screen antialiased">

    <div id="login-modal" class="fixed inset-0 bg-gray-900 bg-opacity-95 z-50 flex items-center justify-center p-4">
        <div class="bg-gray-800 p-8 rounded-xl shadow-2xl w-full max-w-sm">
            <h2 class="text-3xl font-bold mb-6 text-center text-indigo-400">AI Simulator</h2>
            <form id="login-form">
                <div class="mb-4">
                    <label for="username" class="block text-sm font-medium text-gray-300 mb-1">Username</label>
                    <input type="text" id="username" class="w-full px-4 py-2 bg-gray-700 border border-gray-600 rounded-lg focus:ring-indigo-500 focus:border-indigo-500 text-white" required>
                </div>
                <div class="mb-6">
                    <label for="password" class="block text-sm font-medium text-gray-300 mb-1">Password</label>
                    <input type="password" id="password" class="w-full px-4 py-2 bg-gray-700 border border-gray-600 rounded-lg focus:ring-indigo-500 focus:border-indigo-500 text-white" required>
                </div>
                <button type="submit" class="w-full py-2 px-4 bg-indigo-600 hover:bg-indigo-700 rounded-lg font-semibold transition duration-150">
                    Log In (Any Input Works)
                </button>
                <p id="login-status" class="text-sm mt-4 text-center text-red-400 hidden">Login failed. Please try again.</p>
            </form>
        </div>
    </div>

    <header class="bg-gray-800 shadow-md p-4 flex items-center justify-between z-10">
        <h1 class="text-xl font-bold text-indigo-400">Ultimate Client-Side AI Simulator</h1>
        <div class="flex items-center space-x-4">
            <span id="user-display" class="text-sm text-gray-400 hidden">Logged in as: <span id="logged-in-user" class="font-semibold text-white"></span></span>
            <button id="logout-button" class="text-sm text-red-400 hover:text-red-500 hidden transition duration-150">Logout</button>
        </div>
    </header>

    <div id="chat-window" class="flex-grow p-4 space-y-4 overflow-y-auto">
        </div>

    <div id="drop-zone" class="absolute inset-0 bg-indigo-900/50 border-4 border-dashed border-indigo-400 items-center justify-center text-2xl font-bold text-indigo-200 hidden pointer-events-none">
        DROP IMAGE TO RUN VISION TOOL
    </div>

    <div id="chat-input-container" class="p-4 bg-gray-800 flex items-center">
        <input type="text" id="chat-input" placeholder="Ask a question or request a tool (e.g., 'classify the image' or 'plot y=x^2')" class="flex-grow px-4 py-3 bg-gray-700 border border-gray-600 rounded-l-lg focus:outline-none focus:ring-indigo-500 focus:border-indigo-500 text-white text-base">
        <button id="send-button" class="px-6 py-3 bg-indigo-600 hover:bg-indigo-700 text-white font-semibold rounded-r-lg transition duration-150">
            Send
        </button>
    </div>

    <div id="tool-assets" class="hidden">
        <img id="opencv-input-img" alt="Input for OpenCV.js" style="display: none;">
        <canvas id="opencv-output-canvas" style="display: none;"></canvas>
        <div id="d3-output-container"></div>
    </div>

    <script>
        // Global State
        let isLoggedIn = false;
        let model; // For MobileNet
        let cvReady = false; // For OpenCV.js

        // --- OpenCV Initialization Handler ---
        function onOpenCvReady() {
            if (typeof cv !== 'undefined' && cv.getBuildInformation) {
                console.log("OpenCV.js is ready.");
                cvReady = true;
            } else {
                console.warn("OpenCV.js failed to load.");
            }
        }

        // --- UI Setup & Logic ---

        function appendMessage(sender, message, isHtml = false) {
            const chatWindow = document.getElementById('chat-window');
            const messageElement = document.createElement('div');
            messageElement.className = `max-w-3xl p-3 rounded-xl shadow-lg break-words transition-all duration-300 ${
                sender === 'user' ? 'chat-message-user ml-auto' : 'chat-message-ai mr-auto'
            }`;
            if (isHtml) {
                messageElement.innerHTML = message;
            } else {
                messageElement.innerText = message;
            }
            chatWindow.appendChild(messageElement);
            chatWindow.scrollTop = chatWindow.scrollHeight;
            renderMathInElement(messageElement, { delimiters: [{left: "$$", right: "$$", display: true}, {left: "$", right: "$", display: false}] });
        }

        // --- Core Tool Functions ---

        const KNOWLEDGE_BASE = [
            { tool: 'clientSideML', desc: 'Identify and classify an image using the local MobileNet model. (Trained on 1000 categories).', example: 'What do you see in the uploaded image?', trigger: ['classify', 'identify', 'mobilenet', 'see in the image'] },
            { tool: 'clientSideVision', desc: 'Perform basic image processing tasks on an uploaded image using OpenCV.js. Currently supports grayscale and edge detection.', example: 'Run edge detection on the image.', trigger: ['vision', 'opencv', 'grayscale', 'edge detection'] },
            { tool: 'clientSideMath', desc: 'Solve complex mathematical expressions or equations using the math.js library.', example: 'Solve for x: $x^2 + 2x = 3$.', trigger: ['solve', 'calculate', 'math', 'equation'] },
            { tool: 'clientSidePlot', desc: 'Generate a 2D line plot for a given function (e.g., $y=f(x)$) using Plotly.js.', example: 'Plot the function $y = \\sin(x) / x$ from $x=-10$ to $x=10$.', trigger: ['plot', 'graph', 'chart'] },
            { tool: 'clientSideD3Visualization', desc: 'Generate a bar chart visualization for a given array of numbers using D3.js.', example: 'Visualize the data [10, 50, 25, 75, 40].', trigger: ['visualize', 'd3', 'data visualization', 'bar chart'] },
            { tool: 'clientSidePhysics', desc: 'Simulate a physical system (e.g., falling objects, collisions) using Three.js and Cannon.js.', example: 'Simulate a bouncing cube in a 3D environment.', trigger: ['physics', 'simulate', '3d'] },
            { tool: 'mockCodeExecution', desc: 'Simulate the execution of code (e.g., Python, JavaScript) in a secure, sandboxed environment.', example: 'Execute Python: print(2+2).', trigger: ['execute', 'run code', 'code execution'] },
            { tool: 'mockImageGeneration', desc: 'Simulate the generation of a complex image based on a text prompt.', example: 'Generate an image of a futuristic city at sunset.', trigger: ['generate image', 'draw', 'create a picture'] },
            { tool: 'mockAPICall', desc: 'Simulate fetching real-time data from an external API (e.g., weather, stock prices).', example: 'What is the current weather in London?', trigger: ['weather', 'stock price', 'api'] },
        ];


        async function clientSideML(fileDataUrl, fileDetails) {
            if (!model) {
                return `**ML Tool Error:** MobileNet model not loaded. Please wait and try again.`;
            }
            
            return new Promise(resolve => {
                const img = new Image();
                img.onload = async () => {
                    const predictions = await model.classify(img);
                    const results = predictions.slice(0, 3).map(p => 
                        `**${(p.probability * 100).toFixed(2)}%** confidence for **${p.className}**`
                    ).join('\n');

                    const output = `
                        <div class="p-2 border border-green-700 bg-green-900/50 rounded-lg">
                            <p class="text-sm font-semibold text-green-400 mb-1">MobileNet Model Output:</p>
                            <p class="text-xs text-gray-300 mb-2">Analyzed file: ${fileDetails.name}</p>
                            <img src="${fileDataUrl}" alt="Uploaded Image" class="max-w-full h-auto max-h-32 object-contain rounded mb-2">
                            <p class="text-sm">${results}</p>
                        </div>
                    `;
                    resolve(output);
                };
                img.src = fileDataUrl;
            });
        }

        // --- UPDATED: REAL OpenCV.js Vision Tool ---
        async function clientSideVision(fileDataUrl, fileDetails, input) {
            if (!cvReady) {
                return `**Vision Tool Error:** OpenCV.js is not loaded. Please wait and try refreshing.`;
            }

            const imgElement = document.getElementById('opencv-input-img');
            const canvasOutput = document.getElementById('opencv-output-canvas');
            
            return new Promise((resolve) => {
                imgElement.onload = function() {
                    try {
                        let src = cv.imread(imgElement);
                        let dst = new cv.Mat();
                        let resultType;

                        // Check for specific instruction in user input
                        if (input.toLowerCase().includes("edge") || input.toLowerCase().includes("canny")) {
                            // Canny Edge Detection
                            cv.cvtColor(src, src, cv.COLOR_RGBA2GRAY, 0);
                            cv.Canny(src, dst, 50, 100, 3, false);
                            resultType = "Canny Edge Detection";
                        } else {
                            // Default to Grayscale Conversion
                            cv.cvtColor(src, dst, cv.COLOR_RGBA2GRAY, 0);
                            resultType = "Grayscale Conversion";
                        }

                        // Display the result on the hidden canvas
                        cv.imshow('opencv-output-canvas', dst);

                        // Get the Data URL from the canvas
                        const processedDataUrl = canvasOutput.toDataURL('image/png');
                        
                        // Clean up the matrices
                        src.delete();
                        dst.delete();

                        // Construct the chat output
                        const output = `
                            <div class="p-2 border border-gray-700 bg-gray-800 rounded-lg max-w-sm mx-auto">
                                <p class="text-sm font-semibold text-teal-400 mb-2">OpenCV.js Tool Output: ${resultType}</p>
                                <img src="${processedDataUrl}" alt="${resultType}" class="w-full h-auto rounded">
                                <p class="text-xs text-gray-400 mt-2">Processed image: ${fileDetails.name} (${resultType})</p>
                            </div>
                        `;
                        resolve(output);

                    } catch (e) {
                        console.error("OpenCV.js Processing Error:", e);
                        resolve(`**Vision Tool Error:** Failed to process image with OpenCV.js. Error: ${e.message}`);
                    }
                };
                // Trigger the onload by setting the source
                imgElement.src = fileDataUrl;
            });
        }


        async function clientSideMath(input) {
            const match = input.match(/\$([^$]+)\$/) || input.match(/equation:\s*(.*)/i);
            const expr = match ? match[1].trim() : input.trim();
            if (!expr) return `**Math Tool Error:** Please provide an expression to solve or calculate.`;

            try {
                // Remove LaTeX elements for math.js (e.g., \\sin -> sin)
                const mathJsExpr = expr.replace(/\\/g, ''); 
                const result = math.evaluate(mathJsExpr);
                
                let output = `**Math Tool Output:**\n\n\`Input: ${expr}\`\n\n`;

                if (typeof result === 'object' && 'entries' in result) {
                    // Handle array or matrix results
                    output += `\`Result:\n${JSON.stringify(result.entries, null, 2)}\``;
                } else if (typeof result === 'function') {
                    // Handle functions (e.g., 'f(x) = x^2')
                    output += `\`Result: Function defined.\``;
                } else {
                    // Standard numerical result
                    output += `$$\\text{Result} \\approx ${math.format(result, {precision: 10})}$$`;
                }

                return output;

            } catch (e) {
                return `**Math Tool Error:** Failed to evaluate expression: ${e.message}`;
            }
        }


        async function clientSidePlot(input) {
            const exprMatch = input.match(/plot.*?(y|f\(x\))\s*=\s*(.*)/i);
            if (!exprMatch) return `**Plot Tool Error:** Please provide a function to plot in the format 'plot y = f(x)'.`;

            const functionString = exprMatch[2].trim().replace(/\\/g, ''); // Remove latex backslashes
            
            const rangeMatch = input.match(/x=(-?\d+)\s*to\s*x=(-?\d+)/i);
            const xMin = rangeMatch ? parseFloat(rangeMatch[1]) : -5;
            const xMax = rangeMatch ? parseFloat(rangeMatch[2]) : 5;

            try {
                const f = math.compile(functionString);
                const xValues = [];
                const yValues = [];
                
                const steps = 100;
                const stepSize = (xMax - xMin) / steps;

                for (let i = 0; i <= steps; i++) {
                    const x = xMin + i * stepSize;
                    const y = f.evaluate({ x: x });
                    
                    if (isFinite(y)) {
                        xValues.push(x);
                        yValues.push(y);
                    }
                }
                
                const plotId = 'plot-' + Date.now();
                const plotContainer = `<div id="${plotId}" class="w-full h-80 bg-gray-700/50 rounded-lg my-2"></div>`;

                // Return HTML first, then draw the plot
                setTimeout(() => {
                    const data = [{ x: xValues, y: yValues, mode: 'lines', name: functionString }];
                    const layout = {
                        title: `Plot of y = ${functionString}`,
                        xaxis: { title: 'x', range: [xMin, xMax], gridcolor: '#4b5563' },
                        yaxis: { title: 'y', gridcolor: '#4b5563' },
                        paper_bgcolor: '#1f2937', // gray-800
                        plot_bgcolor: '#374151', // gray-700
                        font: { color: '#e5e7eb' }
                    };
                    Plotly.newPlot(plotId, data, layout, {responsive: true});
                }, 10);

                return `**Plot Tool Output:**\n\n<div class="p-2 border border-blue-700 bg-blue-900/50 rounded-lg max-w-lg mx-auto">${plotContainer}<p class="text-xs text-gray-400 mt-2">Plotted function $y = ${functionString}$ from $x=${xMin}$ to $x=${xMax}$.</p></div>`;
            } catch (e) {
                return `**Plot Tool Error:** Failed to plot function. Check your syntax. Error: ${e.message}`;
            }
        }

        // --- ADDED: REAL D3.js Visualization Tool ---
        async function clientSideD3Visualization(input) {
            const dataMatch = input.match(/\[(\s*[^,]+,\s*[^,]+,\s*[^,]+(\s*,\s*[^,]+)*\s*)\]/);
            let data = [40, 60, 20, 80, 50, 70]; // Default data
            let dataUsed = data;

            if (dataMatch) {
                try {
                    // Safely parse array-like string (e.g., "[10, 20, 30]")
                    const parsedData = JSON.parse('[' + dataMatch[1] + ']').map(Number);
                    if (parsedData.every(n => !isNaN(n))) {
                        dataUsed = parsedData;
                    } else {
                        throw new Error("Contains non-numeric data.");
                    }
                } catch (e) {
                    // If parsing fails, stick to default data and inform user
                }
            }
            
            const d3Output = document.getElementById('d3-output-container');
            d3Output.innerHTML = ''; // Clear previous chart

            const width = 300;
            const height = 150;
            const margin = { top: 10, right: 10, bottom: 20, left: 30 };
            
            // 1. Create SVG container (D3.js logic)
            const svg = d3.select(d3Output).append("svg")
                .attr("width", width)
                .attr("height", height)
                .style("background", "rgba(0, 0, 0, 0.1)")
                .append("g")
                .attr("transform", `translate(${margin.left}, ${margin.top})`);
                
            // 2. Define scales
            const x = d3.scaleBand()
                .range([0, width - margin.left - margin.right])
                .domain(dataUsed.map((d, i) => i))
                .padding(0.1);

            const y = d3.scaleLinear()
                .domain([0, d3.max(dataUsed) || 100])
                .range([height - margin.top - margin.bottom, 0]);

            // 3. Draw bars
            svg.selectAll(".bar")
                .data(dataUsed)
                .enter().append("rect")
                .attr("class", "bar")
                .attr("x", (d, i) => x(i))
                .attr("width", x.bandwidth())
                .attr("y", d => y(d))
                .attr("height", d => (height - margin.top - margin.bottom) - y(d))
                .style("fill", "#6366f1"); // Indigo-500

            // 4. Add Axes (Simplified)
            svg.append("g")
                .attr("transform", `translate(0, ${height - margin.top - margin.bottom})`)
                .call(d3.axisBottom(x).tickFormat(i => `Item ${i + 1}`).tickSizeOuter(0))
                .style("font-size", "8px")
                .style("color", "#9ca3af"); // gray-400

            svg.append("g")
                .call(d3.axisLeft(y).ticks(5))
                .style("font-size", "8px")
                .style("color", "#9ca3af"); // gray-400
                
            // Get the SVG content to inject into chat
            const chartHtml = d3Output.innerHTML;
            d3Output.innerHTML = ''; // Clear the hidden container again

            const output = `
                <div class="p-2 border border-indigo-700 bg-indigo-900/50 rounded-lg max-w-sm mx-auto">
                    <p class="text-sm font-semibold text-indigo-400 mb-2">D3.js Data Visualization Tool Output</p>
                    ${chartHtml}
                    <p class="text-xs text-gray-400 mt-2">Drawn a Bar Chart for data: ${JSON.stringify(dataUsed)}</p>
                </div>
            `;
            return output;
        }

        // --- MOCK Tool Functions ---

        async function clientSidePhysics(input) {
            // Placeholder: A real implementation would set up a Three.js scene and a Cannon.js world.
            return `**Physics Tool Output (Mock):** A 3D simulation of a bouncing cube was successfully loaded in a separate viewport (not visible in chat log). It is running at 60 FPS using **Three.js** and **Cannon.js**. Simulation time: 5.0 seconds.`;
        }

        async function mockCodeExecution(input) {
            // Placeholder: A real implementation would involve a Web Worker or a serverless function.
            const langMatch = input.match(/execute\s+(python|javascript|js):\s*(.*)/i);
            const lang = langMatch ? langMatch[1] : 'Unknown';
            const code = langMatch ? langMatch[2].trim() : 'print("Hello, world!")';
            const result = lang.toLowerCase() === 'python' ? '4' : '4'; // Simple mock result
            
            return `**Code Execution Tool Output (Mock):**\n\n**Language:** ${lang}\n\n\`\`\`${lang.toLowerCase()}\n${code}\n\`\`\`\n\n**Result:** Execution complete. Output: \`${result}\``;
        }

        async function mockImageGeneration(input) {
            // Placeholder: A real implementation would use an LLM/Diffusion model API.
            const prompt = input.replace(/generate an image of|create a picture of/i, '').trim();
            const images = [
                'https://picsum.photos/seed/a/200/200',
                'https://picsum.photos/seed/b/200/200',
                'https://picsum.photos/seed/c/200/200'
            ];
            const randomImage = images[Math.floor(Math.random() * images.length)];

            const output = `
                <div class="p-2 border border-pink-700 bg-pink-900/50 rounded-lg max-w-xs mx-auto">
                    <p class="text-sm font-semibold text-pink-400 mb-2">Image Generation Tool Output (Mock)</p>
                    <img src="${randomImage}" alt="Generated image based on prompt" class="w-full h-auto rounded">
                    <p class="text-xs text-gray-400 mt-2">Prompt: **${prompt}**</p>
                </div>
            `;
            return output;
        }

        async function mockAPICall(input) {
            // Placeholder: A real implementation would use the browser's fetch API to hit a data source.
            if (input.toLowerCase().includes('weather')) {
                return `**API Tool Output (Mock):** Weather data retrieved. The current weather in **London** is **15Â°C** and **Partly Cloudy**. (Source: MockWeatherAPI)`;
            } else if (input.toLowerCase().includes('stock')) {
                return `**API Tool Output (Mock):** Stock data retrieved. **GOOG** is trading at **$175.45**, up **+1.2%** today. (Source: MockStockExchange)`;
            }
            return `**API Tool Output (Mock):** Data retrieved successfully, but the content is generic.`;
        }


        // --- Message Dispatch ---

        async function sendMessage(input, fileDetails = null) {
            NProgress.start();
            const cleanedInput = typeof input === 'string' ? input.trim() : '';

            if (cleanedInput) {
                appendMessage('user', cleanedInput);
            }
            if (fileDetails) {
                appendMessage('user', `**File Uploaded:** ${fileDetails.name} (${(fileDetails.size / 1024).toFixed(2)} KB)`, true);
            }

            const chatWindow = document.getElementById('chat-window');
            const thinkingElement = document.createElement('div');
            thinkingElement.className = 'max-w-xs p-3 rounded-xl shadow-lg break-words chat-message-ai mr-auto';
            thinkingElement.innerHTML = '<span class="animate-pulse">Thinking...</span>';
            chatWindow.appendChild(thinkingElement);
            chatWindow.scrollTop = chatWindow.scrollHeight;

            let response = `**Default Response:** I don't have a specific tool for that request. Try asking for one of my available tools.`;
            let toolUsed = false;

            // 1. Tool Matching Logic
            const lowerInput = cleanedInput.toLowerCase();
            let toolToUse = null;

            for (const item of KNOWLEDGE_BASE) {
                if (item.trigger.some(trigger => lowerInput.includes(trigger))) {
                    toolToUse = item.tool;
                    break;
                }
            }

            // 2. Tool Execution
            if (fileDetails) {
                if (toolToUse === 'clientSideML' || lowerInput.includes('classify')) {
                    response = await clientSideML(input, fileDetails);
                    toolUsed = true;
                } else if (toolToUse === 'clientSideVision' || lowerInput.includes('vision')) {
                    response = await clientSideVision(input, fileDetails, cleanedInput);
                    toolUsed = true;
                } else {
                    response = `I received an image but don't know what to do with it. Try asking me to **classify** or run **vision** on it.`;
                }
            } else if (toolToUse) {
                switch (toolToUse) {
                    case 'clientSideMath':
                        response = await clientSideMath(cleanedInput);
                        break;
                    case 'clientSidePlot':
                        response = await clientSidePlot(cleanedInput);
                        break;
                    case 'clientSideD3Visualization':
                        response = await clientSideD3Visualization(cleanedInput);
                        break;
                    case 'clientSidePhysics':
                        response = await clientSidePhysics(cleanedInput);
                        break;
                    case 'mockCodeExecution':
                        response = await mockCodeExecution(cleanedInput);
                        break;
                    case 'mockImageGeneration':
                        response = await mockImageGeneration(cleanedInput);
                        break;
                    case 'mockAPICall':
                        response = await mockAPICall(cleanedInput);
                        break;
                    default:
                        // Fallback to default response if a trigger matched but the tool isn't implemented
                        response = `**AI Error:** Matched a tool (**${toolToUse}**) but the function is unavailable.`;
                }
                toolUsed = true;
            }

            // 3. System Help/Knowledge Base
            if (!toolUsed) {
                if (lowerInput.includes('help') || lowerInput.includes('tools') || lowerInput.includes('capabilities')) {
                    const toolsList = KNOWLEDGE_BASE.map(item => 
                        `**${item.tool}**: ${item.desc}. *Example: "${item.example}"*`
                    ).join('\n\n');
                    response = `**System Capabilities:**\n\nI can access several powerful client-side and mock tools:\n\n${toolsList}`;
                } else if (lowerInput.includes('hello') || lowerInput.includes('hi')) {
                    response = `Hello! I am the **Ultimate Client-Side AI Simulator**. I can run local ML, math, plotting, vision, and physics simulations. Try asking me to **plot y=x^3** or **visualize the data [1, 2, 3]**.`;
                }
            }

            // 4. Final Display
            thinkingElement.remove();
            appendMessage('ai', response, true);
            NProgress.done();
            document.getElementById('chat-input').value = '';
        }

        // --- Initialization ---

        async function loadMobileNet() {
            NProgress.start();
            try {
                model = await mobilenet.load();
                appendMessage('ai', `**System Update:** MobileNet model loaded successfully. Ready for **clientSideML** tasks.`);
            } catch (e) {
                appendMessage('ai', `**System Error:** Failed to load MobileNet model: ${e.message}`);
            }
            NProgress.done();
        }

        function initializeChatbotUI() {
            document.getElementById('login-modal').classList.add('hidden');
            document.getElementById('user-display').classList.remove('hidden');
            document.getElementById('logout-button').classList.remove('hidden');
            document.getElementById('logged-in-user').textContent = localStorage.getItem('username');
            
            appendMessage('ai', 'Welcome! I am the **Ultimate Client-Side AI Simulator**. Ask me for **help** to see my capabilities, or upload an image and ask me to **classify** it.');

            const sendButton = document.getElementById('send-button');
            const chatInput = document.getElementById('chat-input');
            
            sendButton.addEventListener('click', () => {
                const input = chatInput.value;
                if (input.trim()) {
                    sendMessage(input);
                }
            });

            chatInput.addEventListener('keydown', (e) => {
                if (e.key === 'Enter' && chatInput.value.trim()) {
                    sendMessage(chatInput.value);
                }
            });

            // Start loading models
            loadMobileNet();
            setupDragAndDrop();
        }

        function validateLogin(e) {
            e.preventDefault();
            const username = document.getElementById('username').value;
            // Simple client-side mock login: any input is accepted
            localStorage.setItem('username', username || 'User');
            isLoggedIn = true;
            initializeChatbotUI();
        }

        function handleLogout() {
            localStorage.removeItem('username');
            isLoggedIn = false;
            window.location.reload();
        }

        document.addEventListener('DOMContentLoaded', () => {
            const storedUsername = localStorage.getItem('username');
            const loginForm = document.getElementById('login-form');
            const logoutButton = document.getElementById('logout-button');

            if (storedUsername) {
                isLoggedIn = true;
                initializeChatbotUI();
            } else {
                if (loginForm) {
                    loginForm.addEventListener('submit', validateLogin);
                }
            }
            
            if (logoutButton) {
                logoutButton.addEventListener('click', handleLogout);
            }
        });

        // --- Drag and Drop Logic for Vision/ML Tools ---

        function setupDragAndDrop() {
            const dropZone = document.getElementById('drop-zone');

            function preventDefaults(e) {
                e.preventDefault();
                e.stopPropagation();
            }

            function highlight(e) {
                if (e.target === document.body) {
                    dropZone.classList.remove('hidden');
                    dropZone.classList.add('flex');
                }
            }

            function unhighlight(e) {
                dropZone.classList.add('hidden');
                dropZone.classList.remove('flex');
            }
            
            // Fix: Only apply unhighlight on dragleave outside the drop zone or on drop
            document.addEventListener('dragleave', (e) => {
                if (!dropZone || !dropZone.contains(e.target)) {
                    unhighlight(e);
                }
            }, false);

            ['dragenter', 'dragover', 'dragleave', 'drop'].forEach(eventName => {
                document.addEventListener(eventName, preventDefaults, false);
            });

            ['dragenter', 'dragover'].forEach(eventName => {
                document.addEventListener(eventName, highlight, false);
            });

            document.addEventListener('drop', handleDrop, false);

            function handleDrop(e) {
                unhighlight(e);
                const dt = e.dataTransfer;
                const files = dt.files;

                if (files.length > 0) {
                    const file = files[0];
                    if (file.type.startsWith('image/')) {
                        const reader = new FileReader();
                        reader.onload = function(event) {
                            const fileDataUrl = event.target.result;
                            const fileDetails = { name: file.name, size: file.size, type: file.type };
                            // Pass the file data and details to sendMessage
                            // The input box content is taken as the prompt to guide the tool selection
                            sendMessage(fileDataUrl, fileDetails); 
                        };
                        reader.readAsDataURL(file);
                    } else {
                        alert("Only image files are supported for ML analysis.");
                    }
                }
            }
        }
    </script>
</body>
</html>
